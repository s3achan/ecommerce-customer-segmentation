{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c569f0e-ce57-4e2e-ae9e-14ae9f8c5578",
   "metadata": {},
   "source": [
    "<h1> Evaluation Technique </h1>\n",
    "<h4 style=\"color:#555; margin-top:-8px;\">\n",
    "<hr style=\"border:1px solid #ddd;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984f6519-150c-423e-8254-1d44ffddc245",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 3px solid #64748b; padding: 8px 0; margin: 25px 0;\">\n",
    "<h3>      What is a Confusion Matrix? </h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f532cd-8426-4688-b650-3bd8a80d8284",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#fff9c4; padding:16px; border-radius:8px; border-left:5px solid #fbc02d;\">\n",
    "<h3>Definition: </h3> A Confusion Matrix is a table that shows how well a classification model performs by comparing: Actual values and Predicted values. It helps us see where the model is making mistakes.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b46b04-017d-4b37-8936-33f4f50ec9a4",
   "metadata": {},
   "source": [
    "A Confusion Matrix is a table that shows how well a classification model performs by comparing: Actual values and Predicted values.\n",
    "It helps us see where the model is making mistakes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac5720c-83d0-43e4-9be4-3b631e80b099",
   "metadata": {},
   "source": [
    "<div style=\"display: grid;\n",
    "            grid-template-columns: 150px 150px 150px;\n",
    "            text-align: center;\n",
    "            font-family: Arial;\n",
    "            border-collapse: collapse;\">\n",
    "\n",
    "  <div></div>\n",
    "  <div style=\"font-weight:bold; background:#f2f2f2; padding:8px;\">Predicted Positive</div>\n",
    "  <div style=\"font-weight:bold; background:#f2f2f2; padding:8px;\">Predicted Negative</div>\n",
    "\n",
    "  <div style=\"font-weight:bold; background:#f2f2f2; padding:8px;\">Actual Positive</div>\n",
    "  <div style=\"padding:8px; border:1px solid #ccc;\">TP</div>\n",
    "  <div style=\"padding:8px; border:1px solid #ccc;\">FN</div>\n",
    "\n",
    "  <div style=\"font-weight:bold; background:#f2f2f2; padding:8px;\">Actual Negative</div>\n",
    "  <div style=\"padding:8px; border:1px solid #ccc;\">FP</div>\n",
    "  <div style=\"padding:8px; border:1px solid #ccc;\">TN</div>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b4fd03-9c2a-435f-bf78-ea6935aa47af",
   "metadata": {},
   "source": [
    "<h2>Meaning of Each Term</h2>\n",
    "\n",
    "<div style=\"background:#e8f5e9; padding:12px; border-radius:8px; margin-bottom:10px;\">\n",
    "  <strong>‚úÖ True Positive (TP)</strong><br>\n",
    "  Model predicted <b>Yes</b>, and it was actually <b>Yes</b>.\n",
    "</div>\n",
    "\n",
    "<div style=\"background:#fdecea; padding:12px; border-radius:8px; margin-bottom:10px;\">\n",
    "  <strong>‚ùå False Positive (FP)</strong><br>\n",
    "  Model predicted <b>Yes</b>, but actually <b>No</b>.<br>\n",
    "  <em>(Also called Type I Error)</em>\n",
    "</div>\n",
    "\n",
    "<div style=\"background:#fdecea; padding:12px; border-radius:8px; margin-bottom:10px;\">\n",
    "  <strong>‚ùå False Negative (FN)</strong><br>\n",
    "  Model predicted <b>No</b>, but actually <b>Yes</b>.<br>\n",
    "  <em>(Also called Type II Error)</em>\n",
    "</div>\n",
    "\n",
    "<div style=\"background:#e8f5e9; padding:12px; border-radius:8px;\">\n",
    "  <strong>‚úÖ True Negative (TN)</strong><br>\n",
    "  Model predicted <b>No</b>, and it was actually <b>No</b>.\n",
    "</div>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ea8159-ebea-445f-a988-3d3feff991e7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéØ Precision\n",
    "\n",
    "Formula:\n",
    "$\\qquad P r e c i s i o n = \\frac{T P}{T P + F P}$\n",
    "\n",
    "Calculation:\n",
    "$\\qquad P r e c i s i o n = \\frac{3}{3 + 1} = \\frac{3}{4} = 0.75$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e7ac44-3c03-4f78-ab1c-1004407ef0b6",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### üîç What Does It Show?\n",
    "\n",
    "Precision answers the question:\n",
    "\n",
    "> Out of all predicted positives, how many were actually correct?\n",
    "\n",
    "#### ‚ö†Ô∏è When Is Precision Important?\n",
    "\n",
    "Use Precision when **False Positives are costly**.\n",
    "\n",
    "#### Example:\n",
    "- üìß Email spam detection  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d753cc0e-81ae-4d52-9777-4e6922f980af",
   "metadata": {},
   "source": [
    "---\n",
    "## üéØ Recall (Sensitivity)\n",
    "Formula:\n",
    "$\\qquad R e c a l l = \\frac{T P}{T P + F N}$\n",
    "\n",
    "Calculation:\n",
    "$\\qquad R e c a l l = \\frac{3}{3 + 1} = \\frac{3}{4} = 0.75$\n",
    "\n",
    "#### üîç What Does It Show?\n",
    "\n",
    "Recall answers the question:\n",
    "\n",
    "> Out of all actual positives, how many did the model correctly identify?\n",
    "\n",
    "### ‚ö†Ô∏è When Is Recall Important?\n",
    "\n",
    "Use Recall when **False Negatives are costly**.\n",
    "\n",
    "#### Example:\n",
    "- üí≥ Fraud detection  \n",
    "  You don‚Äôt want fraudulent transactions to go undetected.\n",
    "\n",
    "- ü©∫ Disease diagnosis  \n",
    "  Missing a positive case can be dangerous."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0451c28d-fc30-48ef-85b2-c8514e67b917",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéØ F1-Score\n",
    "\n",
    "Formula:\n",
    "$\\qquad F 1 = 2 \\times \\frac{P r e c i s i o n \\times R e c a l l}{P r e c i s i o n + R e c a l l}$\n",
    "\n",
    "Calculation:\n",
    "$\\qquad F 1 = 2 \\times \\frac{0.75 \\times 0.75}{0.75 + 0.75}$\n",
    "\n",
    "$\\qquad F 1 = 2 \\times \\frac{0.5625}{1.5}$\n",
    "\n",
    "$\\qquad F 1 = 2 \\times 0.375 = 0.75$\n",
    "\n",
    "\n",
    "#### üîç What Does It Show?\n",
    "\n",
    "F1-Score balances both Precision and Recall.\n",
    "\n",
    "It answers:\n",
    "\n",
    "> How well does the model perform overall when considering both false positives and false negatives?\n",
    "\n",
    "#### ‚öñÔ∏è When Is F1-Score Important?\n",
    "\n",
    "Use F1-Score when:\n",
    "- You need a balance between Precision and Recall\n",
    "- Classes are imbalanced\n",
    "- Both FP and FN matter\n",
    "\n",
    "#### Example:\n",
    "- Fraud detection\n",
    "- Medical diagnosis\n",
    "- Risk modeling\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82226e2f-e89c-4853-9ca8-cc101dfb1e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[3 1]\n",
      " [1 3]]\n",
      "Precision: 0.75\n",
      "Recall: 0.75\n",
      "F1 Score: 0.75\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "\n",
    "# Small Example Dataset\n",
    "y_true = [1,1,0,0,1,0,1,0]\n",
    "y_pred = [1,0,1,0,1,0,1,0]\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Precision\n",
    "precision = precision_score(y_true, y_pred)\n",
    "print(\"Precision:\", precision)\n",
    "\n",
    "# Recall\n",
    "recall = recall_score(y_true, y_pred)\n",
    "print(\"Recall:\", recall)\n",
    "\n",
    "# F1 Score\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "print(\"F1 Score:\", f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (project)",
   "language": "python",
   "name": "project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
